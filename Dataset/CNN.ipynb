{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import gridspec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Aim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some explation about the purpose of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some insight about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Room</th>\n",
       "      <th>Array_position</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Absorption</th>\n",
       "      <th>SNR</th>\n",
       "      <th>Audio_file</th>\n",
       "      <th>Phase_Matrix</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[3.395545610109257, 2.0550302704519794, 1.5]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702471</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/audio_signals...</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/phase_matrix/...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[3.2402107165724896, 1.8276250338752629, 1.5]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702471</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/audio_signals...</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/phase_matrix/...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.6801067878855174, 1.927483519251545, 1.5]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702471</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/audio_signals...</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/phase_matrix/...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[3.2065269137273935, 3.207686173511143, 1.5]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702471</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/audio_signals...</td>\n",
       "      <td>/home/janjar/Dataset/Trainingset/phase_matrix/...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Room                                 Array_position  Distance  Absorption  \\\n",
       "0    0   [3.395545610109257, 2.0550302704519794, 1.5]       1.0    0.702471   \n",
       "1    0  [3.2402107165724896, 1.8276250338752629, 1.5]       1.0    0.702471   \n",
       "2    0   [1.6801067878855174, 1.927483519251545, 1.5]       1.0    0.702471   \n",
       "3    0   [3.2065269137273935, 3.207686173511143, 1.5]       1.0    0.702471   \n",
       "\n",
       "  SNR                                         Audio_file  \\\n",
       "0   0  /home/janjar/Dataset/Trainingset/audio_signals...   \n",
       "1   0  /home/janjar/Dataset/Trainingset/audio_signals...   \n",
       "2   0  /home/janjar/Dataset/Trainingset/audio_signals...   \n",
       "3   0  /home/janjar/Dataset/Trainingset/audio_signals...   \n",
       "\n",
       "                                        Phase_Matrix Label  \n",
       "0  /home/janjar/Dataset/Trainingset/phase_matrix/...    21  \n",
       "1  /home/janjar/Dataset/Trainingset/phase_matrix/...    32  \n",
       "2  /home/janjar/Dataset/Trainingset/phase_matrix/...     9  \n",
       "3  /home/janjar/Dataset/Trainingset/phase_matrix/...    27  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = pd.read_pickle(\"/home/janjar/Dataset/Trainingset/Training_dataframe.pkl\")\n",
    "Dataset.loc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining our number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rooms = Dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the phase matrices in tensors with respect to the indexing shown in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 4, 129, 390)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path containing the Training data on the machine you are working on.\n",
    "#path = \"/home/janjar/Dataset/Trainingset/\"\n",
    "\n",
    "data_matrix = np.zeros([number_of_rooms,4,129,390])\n",
    "for i in range(number_of_rooms):\n",
    "    fileName_matrix = Dataset.iloc[i]['Phase_Matrix']\n",
    "    fileObject2 = open(fileName_matrix, 'rb')\n",
    "    matrix_loaded = pkl.load(fileObject2)\n",
    "    fileObject2.close()\n",
    "    data_matrix[i] = matrix_loaded\n",
    "data_matrix.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([140, 390, 4, 129])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix = torch.from_numpy(data_matrix)\n",
    "data_matrix = data_matrix.view(-1,390,4,129)\n",
    "data_matrix = data_matrix.type('torch.FloatTensor')\n",
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that reshape a label into the right format for the data_targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_targets(index,label):\n",
    "    target = torch.tensor(label)\n",
    "    target = target.expand(390,1)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([140, 390, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_targets = torch.zeros([number_of_rooms,390,1], dtype=torch.float64)\n",
    "for i in range(number_of_rooms):\n",
    "    data_targets[i] = prep_targets(i,Dataset.iloc[i]['Label'])\n",
    "data_targets.shape   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture 1.0 : vanilla CNN for DOA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will focus on building a vanilla CNN in order to recognize the directions of arrival of the sound in a specific room. Once done, we will then compare \"by hand\" the labelel dataset to the predicted values. This is the most basic setup and will try to improve latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,nb_hidden = 512):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(64 , 64, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(8064, nb_hidden)# (1x8064) being the dim of the censor obtained by flattening the output of the 3rd CL.\n",
    "        self.fc2 = nn.Linear(nb_hidden, 37)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 8064)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "       \n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input_vanilla(train_input):\n",
    "    new_train_input = train_input.view(-1,390,1,1,4,129)\n",
    "    return new_train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([140, 390, 1, 1, 4, 129])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = prep_input_vanilla(data_matrix)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_labels_vanilla(train_input):\n",
    "    new_train_input = train_input.view(-1,390,1)\n",
    "    return new_train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([140, 390, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets = prep_labels_vanilla(data_targets)\n",
    "train_targets = train_targets.to(dtype=torch.int64)\n",
    "train_data, train_targets = Variable(train_data), Variable(train_targets)\n",
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 30 \n",
    "nb_epochs = 5\n",
    "eta = 0.5 #learning rate\n",
    "#criterion = nn.MSELoss() # MeanSquaredloss\n",
    "criterion = torch.nn.CrossEntropyLoss() #Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to figure out how to use mini-batches to gain time in this configuration.\n",
    "#### train_model is the method used to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, criterion, nb_epochs, eta):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = eta, momentum = 0.95) #Stochastic gradient descent\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0)):\n",
    "            for a in range(0,train_input.size(1)):\n",
    "                output = model(train_input[b,a,:,:,:,:])\n",
    "                target = train_target[b,a,:]\n",
    "                #print(\"Output vs target\",output,target)\n",
    "                #loss = criterion(output,target)\n",
    "                loss = criterion(output,target)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "        print(e, loss.data.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2(model, train_input, train_target, mini_batch_size, criterion, nb_epochs, eta):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = eta, momentum = 0.95) #Stochastic gradient descent\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0)):\n",
    "            for a in range(0,train_input.size(1),mini_batch_size):\n",
    "                output = model(train_input[b].narrow(0, a, mini_batch_size))\n",
    "                #print(output.shape)\n",
    "                target = train_targets[b].narrow(0, a, mini_batch_size)\n",
    "                #print(target.shape)\n",
    "                #loss = criterion(output,target)\n",
    "                loss = criterion(output,targets.max(1)[1])\n",
    "                print(b,target.max(1)[1])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        print(e, loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janjar/test/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.610917806625366\n"
     ]
    }
   ],
   "source": [
    "train_model(model,train_data,train_targets,mini_batch_size,criterion,nb_epochs,eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semesterproject",
   "language": "python",
   "name": "semesterproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
